Args in experiment:
Namespace(batch_size=256, c_out=7, checkpoints='./checkpoints/', d_model=512, data='ETTh2', data_path='ETTh2.csv', dec_in=7, des='Exp', devices='0,1', dropout=0.0, enc_in=7, features='M', freq='h', gpu=0, is_training=1, itr=1, label_len=48, layers=3, learning_rate=1e-05, loss='mse', lradj='constant', model='LiNo', model_id='ETTh2_96_96', num_workers=0, patience=6, pred_len=96, root_path='./dataset/ETT-small/', seq_len=96, target='OT', task_name='long_term_forecast', train_epochs=50, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
Model total parameters: 5.29 M

>>>>>>>start training : LiNo_ETTh2_sl96_pl96_lr1e-05_layers_3_dp0.0_dm512>>>>>>>>>>>>>>>>>>>>>>>>>>

train 8449
val 2785
test 2785
Epoch: 1 cost time: 1.9265148639678955
Epoch: 1, Steps: 34 | Train Loss: 0.4962339 Val Loss: 0.2429291 Test Loss: 0.3226287
Validation loss decreased (inf --> 0.242929).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.0565407276153564
Epoch: 2, Steps: 34 | Train Loss: 0.4488022 Val Loss: 0.2300456 Test Loss: 0.3096459
Validation loss decreased (0.242929 --> 0.230046).  Saving model ...
Updating learning rate to 1e-05
Epoch: 3 cost time: 1.0576698780059814
Epoch: 3, Steps: 34 | Train Loss: 0.4266178 Val Loss: 0.2238715 Test Loss: 0.3027838
Validation loss decreased (0.230046 --> 0.223871).  Saving model ...
Updating learning rate to 1e-05
Epoch: 4 cost time: 1.1612484455108643
Epoch: 4, Steps: 34 | Train Loss: 0.5350892 Val Loss: 0.2193124 Test Loss: 0.2978618
Validation loss decreased (0.223871 --> 0.219312).  Saving model ...
Updating learning rate to 1e-05
Epoch: 5 cost time: 1.2740600109100342
Epoch: 5, Steps: 34 | Train Loss: 0.4142617 Val Loss: 0.2213017 Test Loss: 0.2986607
EarlyStopping counter: 1 out of 6
Updating learning rate to 1e-05
Epoch: 6 cost time: 1.4364452362060547
Epoch: 6, Steps: 34 | Train Loss: 0.4123392 Val Loss: 0.2183869 Test Loss: 0.2963885
Validation loss decreased (0.219312 --> 0.218387).  Saving model ...
Updating learning rate to 1e-05
Epoch: 7 cost time: 1.2995648384094238
Epoch: 7, Steps: 34 | Train Loss: 0.4071267 Val Loss: 0.2169541 Test Loss: 0.2953632
Validation loss decreased (0.218387 --> 0.216954).  Saving model ...
Updating learning rate to 1e-05
Epoch: 8 cost time: 1.5518255233764648
Epoch: 8, Steps: 34 | Train Loss: 0.4146687 Val Loss: 0.2161911 Test Loss: 0.2947471
Validation loss decreased (0.216954 --> 0.216191).  Saving model ...
Updating learning rate to 1e-05
Epoch: 9 cost time: 1.7141211032867432
Epoch: 9, Steps: 34 | Train Loss: 0.4021615 Val Loss: 0.2156068 Test Loss: 0.2941657
Validation loss decreased (0.216191 --> 0.215607).  Saving model ...
Updating learning rate to 1e-05
Epoch: 10 cost time: 2.0970351696014404
Epoch: 10, Steps: 34 | Train Loss: 0.4116824 Val Loss: 0.2151336 Test Loss: 0.2935743
Validation loss decreased (0.215607 --> 0.215134).  Saving model ...
Updating learning rate to 1e-05
Epoch: 11 cost time: 2.0677781105041504
Epoch: 11, Steps: 34 | Train Loss: 0.3982081 Val Loss: 0.2152763 Test Loss: 0.2926207
EarlyStopping counter: 1 out of 6
Updating learning rate to 1e-05
Epoch: 12 cost time: 2.174950122833252
Epoch: 12, Steps: 34 | Train Loss: 0.4001681 Val Loss: 0.2148063 Test Loss: 0.2926121
Validation loss decreased (0.215134 --> 0.214806).  Saving model ...
Updating learning rate to 1e-05
Epoch: 13 cost time: 2.2292816638946533
Epoch: 13, Steps: 34 | Train Loss: 0.3998603 Val Loss: 0.2146423 Test Loss: 0.2923819
Validation loss decreased (0.214806 --> 0.214642).  Saving model ...
Updating learning rate to 1e-05
Epoch: 14 cost time: 2.248102903366089
Epoch: 14, Steps: 34 | Train Loss: 0.3954006 Val Loss: 0.2148001 Test Loss: 0.2929923
EarlyStopping counter: 1 out of 6
Updating learning rate to 1e-05
Epoch: 15 cost time: 2.377809762954712
Epoch: 15, Steps: 34 | Train Loss: 0.3936424 Val Loss: 0.2146225 Test Loss: 0.2923150
Validation loss decreased (0.214642 --> 0.214622).  Saving model ...
Updating learning rate to 1e-05
Epoch: 16 cost time: 2.277791976928711
Epoch: 16, Steps: 34 | Train Loss: 0.3888520 Val Loss: 0.2138866 Test Loss: 0.2920084
Validation loss decreased (0.214622 --> 0.213887).  Saving model ...
Updating learning rate to 1e-05
Epoch: 17 cost time: 2.102735757827759
Epoch: 17, Steps: 34 | Train Loss: 0.3901422 Val Loss: 0.2139778 Test Loss: 0.2921976
EarlyStopping counter: 1 out of 6
Updating learning rate to 1e-05
Epoch: 18 cost time: 2.4480056762695312
Epoch: 18, Steps: 34 | Train Loss: 0.3843366 Val Loss: 0.2143327 Test Loss: 0.2919950
EarlyStopping counter: 2 out of 6
Updating learning rate to 1e-05
Epoch: 19 cost time: 2.214360475540161
Epoch: 19, Steps: 34 | Train Loss: 0.3817717 Val Loss: 0.2140462 Test Loss: 0.2924171
EarlyStopping counter: 3 out of 6
Updating learning rate to 1e-05
Epoch: 20 cost time: 2.44187331199646
Epoch: 20, Steps: 34 | Train Loss: 0.4023407 Val Loss: 0.2139213 Test Loss: 0.2930068
EarlyStopping counter: 4 out of 6
Updating learning rate to 1e-05
Epoch: 21 cost time: 2.4288852214813232
Epoch: 21, Steps: 34 | Train Loss: 0.3783220 Val Loss: 0.2152684 Test Loss: 0.2920486
EarlyStopping counter: 5 out of 6
Updating learning rate to 1e-05
Epoch: 22 cost time: 2.412501811981201
Epoch: 22, Steps: 34 | Train Loss: 0.3749760 Val Loss: 0.2143525 Test Loss: 0.2922954
EarlyStopping counter: 6 out of 6
Early stopping
>>>>>>>testing : LiNo_ETTh2_sl96_pl96_lr1e-05_layers_3_dp0.0_dm512<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

test 2785
loading model..............

test shape: (2785, 96, 7) (2785, 96, 7)
mse:0.292, mae:0.340
>>>>>>>visualizing of prediction : LiNo_ETTh2_sl96_pl96_lr1e-05_layers_3_dp0.0_dm512<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

test 2785
loading model..............

>>>>>>>visualizing of layer (Li block and No block) weight : LiNo_ETTh2_sl96_pl96_lr1e-05_layers_3_dp0.0_dm512<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

loading model..............

